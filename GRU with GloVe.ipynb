{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWQGwE3ohRL0"
      },
      "source": [
        "#for data analysis and modeling\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing import text, sequence \n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#for text cleaning\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "#for visualization\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vx30U3ThT-6",
        "outputId": "159bc68b-e9bf-4a8a-b433-67eec854d694"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMezI5ydhei3"
      },
      "source": [
        "trdata=pd.read_csv('/content/drive/MyDrive/QuoraInsecure/train/train.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABt-8kQuhpQh"
      },
      "source": [
        "tesdata=pd.read_csv('/content/drive/MyDrive/QuoraInsecure/test/test.csv')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "Nnd9_8ZuhrrD",
        "outputId": "d3df07ca-5526-43f5-e9d9-e3b90660c717"
      },
      "source": [
        "trdata.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000042bf85aa498cd78e</td>\n",
              "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000455dfa3e01eae3af</td>\n",
              "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  ... target\n",
              "0  00002165364db923c7e6  ...      0\n",
              "1  000032939017120e6e44  ...      0\n",
              "2  0000412ca6e4628ce2cf  ...      0\n",
              "3  000042bf85aa498cd78e  ...      0\n",
              "4  0000455dfa3e01eae3af  ...      0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djplDxHuiN2U",
        "outputId": "b6043246-df6f-400b-dfc6-99273d2348f3"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9YEWPdTiSOJ",
        "outputId": "004f541c-a3b6-41a2-94a8-7285cd5b3370"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2e6wpw6hwIZ",
        "outputId": "266449d0-d7d0-4cae-d195-34c6220753f3"
      },
      "source": [
        "%%time\n",
        "def clean_text(txt):\n",
        "    \"\"\"\"\"\n",
        "    cleans the input text in the following steps\n",
        "    1- replace contractions\n",
        "    2- removing punctuation\n",
        "    3- spliting into words\n",
        "    4- removing stopwords\n",
        "    5- removing leftover punctuations\n",
        "    \"\"\"\"\"\n",
        "    contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "    def _get_contractions(contraction_dict):\n",
        "        contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
        "        return contraction_dict, contraction_re\n",
        "\n",
        "    def replace_contractions(text):\n",
        "        contractions, contractions_re = _get_contractions(contraction_dict)\n",
        "        def replace(match):\n",
        "            return contractions[match.group(0)]\n",
        "        return contractions_re.sub(replace, text)\n",
        "\n",
        "    # replace contractions\n",
        "    txt = replace_contractions(txt)\n",
        "    \n",
        "    #remove punctuations\n",
        "    txt  = \"\".join([char for char in txt if char not in string.punctuation])\n",
        "    txt = re.sub('[0-9]+', '', txt)\n",
        "    \n",
        "    # split into words\n",
        "    words = word_tokenize(txt)\n",
        "    \n",
        "    # remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [w for w in words if not w in stop_words]\n",
        "    \n",
        "    # removing leftover punctuations\n",
        "    words = [word for word in words if word.isalpha()]\n",
        "    \n",
        "    cleaned_text = ' '.join(words)\n",
        "    return cleaned_text\n",
        "    \n",
        "trdata['data_cleaned'] = trdata['question_text'].apply(lambda txt: clean_text(txt))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 49s, sys: 17.8 s, total: 6min 7s\n",
            "Wall time: 6min 6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "kwKPz7C7h2Ya",
        "outputId": "354d0981-1c54-4e9e-bf1b-6ba7332c4eb6"
      },
      "source": [
        "trdata.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "      <th>data_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0</td>\n",
              "      <td>How Quebec nationalists see province nation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0</td>\n",
              "      <td>Do adopted dog would encourage people adopt shop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0</td>\n",
              "      <td>Why velocity affect time Does velocity affect ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000042bf85aa498cd78e</td>\n",
              "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
              "      <td>0</td>\n",
              "      <td>How Otto von Guericke used Magdeburg hemispheres</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000455dfa3e01eae3af</td>\n",
              "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
              "      <td>0</td>\n",
              "      <td>Can I convert montra helicon D mountain bike c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  ...                                       data_cleaned\n",
              "0  00002165364db923c7e6  ...        How Quebec nationalists see province nation\n",
              "1  000032939017120e6e44  ...   Do adopted dog would encourage people adopt shop\n",
              "2  0000412ca6e4628ce2cf  ...  Why velocity affect time Does velocity affect ...\n",
              "3  000042bf85aa498cd78e  ...   How Otto von Guericke used Magdeburg hemispheres\n",
              "4  0000455dfa3e01eae3af  ...  Can I convert montra helicon D mountain bike c...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZoOlemZjDAD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHRLfDdEkp5Z"
      },
      "source": [
        "prepare train and test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkXktVHFkz5o"
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(trdata['data_cleaned'], trdata['target'].values, shuffle=True, test_size=0.2)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSwkH9ZmlIKW",
        "outputId": "ef652501-ebdc-4e18-e889-c4073ffe5e87"
      },
      "source": [
        "max_len = xtrain.apply(lambda x: len(x)).max()\n",
        "print(f'Max number of words in a text in training data: {max_len}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max number of words in a text in training data: 498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0LkPRTLlOWY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOTnDaablUTM"
      },
      "source": [
        "tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgE_Nc6jlVm_",
        "outputId": "2065758f-1397-4f55-8640-406c56014746"
      },
      "source": [
        "max_words = 10000\n",
        "tokenizer = text.Tokenizer(num_words = max_words)\n",
        "# create the vocabulary by fitting on x_train text\n",
        "tokenizer.fit_on_texts(xtrain)\n",
        "# generate the sequence of tokens\n",
        "xtrain_seq = tokenizer.texts_to_sequences(xtrain)\n",
        "xtest_seq = tokenizer.texts_to_sequences(xtest)\n",
        "\n",
        "# pad the sequences\n",
        "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
        "xtest_pad = sequence.pad_sequences(xtest_seq, maxlen=max_len)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "print('text example:', xtrain[0])\n",
        "print('sequence of indices(before padding):', xtrain_seq[0])\n",
        "print('sequence of indices(after padding):', xtrain_pad[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text example: How Quebec nationalists see province nation\n",
            "sequence of indices(before padding): [79, 231, 135, 4182, 2876, 193, 619, 559, 3, 185, 5457, 499]\n",
            "sequence of indices(after padding): [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0   79  231  135 4182\n",
            " 2876  193  619  559    3  185 5457  499]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyjU-Sh1lXpk",
        "outputId": "170a5c56-51b4-420c-9d23-4f2df823a447"
      },
      "source": [
        "%%time\n",
        "embedding_vectors = {}\n",
        "# with open('/kaggle/input/glove6b100d/glove.6B.100d.txt','r',encoding='utf-8') as file:\n",
        "with open('/content/drive/MyDrive/QuoraInsecure/embeddings/glove.840B.300d/glove.840B.300d.txt','r',encoding='utf-8') as file:\n",
        "    for row in file:\n",
        "        values = row.split(' ')\n",
        "        word = values[0]\n",
        "        weights = np.asarray([float(val) for val in values[1:]])\n",
        "        embedding_vectors[word] = weights\n",
        "print(f\"Size of vocabulary in GloVe: {len(embedding_vectors)}\") "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of vocabulary in GloVe: 2196016\n",
            "CPU times: user 3min 15s, sys: 8.26 s, total: 3min 24s\n",
            "Wall time: 3min 38s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7C3i8Sylq8d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqtIh6dHm1dB"
      },
      "source": [
        "embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hEvqtlIm31w",
        "outputId": "740db573-33e6-4a08-881d-e2c9caa190eb"
      },
      "source": [
        "#initialize the embedding_matrix with zeros\n",
        "emb_dim = 300\n",
        "if max_words is not None: \n",
        "    vocab_len = max_words \n",
        "else:\n",
        "    vocab_len = len(word_index)+1\n",
        "embedding_matrix = np.zeros((vocab_len, emb_dim))\n",
        "oov_count = 0\n",
        "oov_words = []\n",
        "for word, idx in word_index.items():\n",
        "    if idx < vocab_len:\n",
        "        embedding_vector = embedding_vectors.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[idx] = embedding_vector\n",
        "        else:\n",
        "            oov_count += 1 \n",
        "            oov_words.append(word)\n",
        "#print some of the out of vocabulary words\n",
        "print(f'Some out of valubulary words: {oov_words[0:5]}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some out of valubulary words: ['quorans', 'cryptocurrencies', 'brexit', 'redmi', 'kvpy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51Z5Y8NOm6gz",
        "outputId": "3f5dd644-7a0f-411f-abd3-0948ccc8078d"
      },
      "source": [
        "print(f'{oov_count} out of {vocab_len} words were OOV.')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55 out of 10000 words were OOV.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX4r_gmAnC1E",
        "outputId": "22a0ac9a-56b3-4f64-f589-26147a11570d"
      },
      "source": [
        "emb_dim = embedding_matrix.shape[1]\n",
        "gru_model = Sequential()\n",
        "gru_model.add(Embedding(vocab_len, emb_dim, trainable = False, weights=[embedding_matrix]))\n",
        "gru_model.add(GRU(128, return_sequences=False))\n",
        "gru_model.add(Dropout(0.5))\n",
        "gru_model.add(Dense(1, activation = 'sigmoid'))\n",
        "gru_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(gru_model.summary())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 300)         3000000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 128)               165120    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 3,165,249\n",
            "Trainable params: 165,249\n",
            "Non-trainable params: 3,000,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQAjhzxKnMiJ",
        "outputId": "4ff08fea-49db-4cb8-ac85-10d0b7afb163"
      },
      "source": [
        "batch_size = 256\n",
        "epochs  = 2\n",
        "history = gru_model.fit(xtrain_pad, np.asarray(ytrain), validation_data=(xtest_pad, np.asarray(ytest)), batch_size = batch_size, epochs = epochs)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4082/4082 [==============================] - 8533s 2s/step - loss: 0.1242 - accuracy: 0.9522 - val_loss: 0.1153 - val_accuracy: 0.9553\n",
            "Epoch 2/2\n",
            "4082/4082 [==============================] - 8498s 2s/step - loss: 0.1136 - accuracy: 0.9559 - val_loss: 0.1125 - val_accuracy: 0.9566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z0BySCmnYxM",
        "outputId": "34e2b79f-4d21-4f98-d080-5d84cd925cdb"
      },
      "source": [
        "train_gru_results = gru_model.evaluate(xtrain_pad, np.asarray(ytrain), verbose=0, batch_size=256)\n",
        "test_gru_results = gru_model.evaluate(xtest_pad, np.asarray(ytest), verbose=0, batch_size=256)\n",
        "print(f'Train accuracy: {train_gru_results[1]*100:0.2f}')\n",
        "print(f'Test accuracy: {test_gru_results[1]*100:0.2f}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 95.85\n",
            "Test accuracy: 95.66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59W_zNHGXN65"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}